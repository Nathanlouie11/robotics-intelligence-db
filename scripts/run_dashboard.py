#!/usr/bin/env python3
"""
Streamlit Dashboard for Robotics Intelligence Database.

Run with: streamlit run scripts/run_dashboard.py
"""

import sys
import os
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import sqlite3
import json
import requests
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

from src.config import DATABASE_PATH, OLLAMA_HOST, OLLAMA_MODEL

# OpenRouter API Configuration (for cloud deployment)
def get_openrouter_key():
    """Get OpenRouter API key from various sources."""
    # 1. Check environment variable
    key = os.getenv('OPENROUTER_KEY')
    if key:
        return key
    # 2. Check Streamlit secrets
    try:
        if hasattr(st, 'secrets') and 'OPENROUTER_KEY' in st.secrets:
            return st.secrets['OPENROUTER_KEY']
    except Exception:
        pass
    # 3. Check session state (user input)
    if 'openrouter_key' in st.session_state and st.session_state.openrouter_key:
        return st.session_state.openrouter_key
    return None

OPENROUTER_MODEL = "google/gemini-2.0-flash-lite-001"

# Page configuration
st.set_page_config(
    page_title="Robotics Intelligence Dashboard",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)


# Database connection (no caching to ensure fresh data)
def get_db_connection():
    """Get a database connection."""
    return sqlite3.connect(DATABASE_PATH, check_same_thread=False)


def run_query(query: str, params: tuple = ()) -> pd.DataFrame:
    """Run a SQL query and return results as DataFrame."""
    conn = get_db_connection()
    return pd.read_sql_query(query, conn, params=params)


def get_schema_info() -> str:
    """Get database schema information for LLM context."""
    schema = """
Database Schema:
- sectors: id, name, description
- subcategories: id, sector_id, name, description
- dimensions: id, name, unit, description
- sources: id, name, url, source_type, reliability_score
  * IMPORTANT: Company names are stored in sources.name
  * Format: "[STARTUP] Company Name..." or "[Company Name] Report Title..."
  * Example: "[STARTUP] Exotec raises $335 million..."
- data_points: id, sector_id, subcategory_id, dimension_id, value, value_text,
               year, quarter, month, source_id, confidence, validation_status, notes
  * value = numeric value (e.g., 335 for $335M)
  * value_text = text description (e.g., "$335M Series B")
- technologies: id, name, category, description, maturity_level
- technology_data_points: id, technology_id, dimension_id, value, value_text, year, confidence

Key dimensions (metrics tracked):
- market_size (USD billions)
- market_growth_rate (percent)
- unit_shipments (units)
- average_selling_price (USD)
- deployment_count (units)
- adoption_rate (percent)
- funding_raised (USD millions) - value is the amount, source.name contains company

Example query for top funded companies:
SELECT src.name as company_source, dp.value as funding_millions, dp.value_text, dp.year
FROM data_points dp
JOIN dimensions dim ON dp.dimension_id = dim.id
JOIN sources src ON dp.source_id = src.id
WHERE dim.name = 'funding_raised'
ORDER BY dp.value DESC LIMIT 10;

Confidence levels: high, medium, low, unverified
Validation status: pending, in_review, validated, rejected, outdated

Sectors: Industrial Robotics, Mobile Robotics, Service Robotics,
         Agricultural Robotics, Logistics Robotics, Construction Robotics
"""
    return schema


def query_ollama(prompt: str, context: str = "") -> str:
    """Query Ollama for natural language processing."""
    system_prompt = f"""You are a helpful assistant for a robotics intelligence database.
You help users query and understand data about the robotics industry.

{get_schema_info()}

When the user asks a question:
1. If they want data, generate a valid SQLite query
2. Wrap SQL queries in ```sql and ``` tags
3. Explain what the query does
4. If they ask for analysis, provide insights based on available data

{context}

Be concise and helpful."""

    try:
        response = requests.post(
            f"{OLLAMA_HOST}/api/generate",
            json={
                "model": OLLAMA_MODEL,
                "prompt": f"{system_prompt}\n\nUser question: {prompt}",
                "stream": False,
                "options": {"temperature": 0.3, "num_predict": 2000}
            },
            timeout=120
        )
        response.raise_for_status()
        return response.json().get("response", "No response from model")
    except requests.exceptions.ConnectionError:
        return "Error: Cannot connect to Ollama. Make sure it's running at " + OLLAMA_HOST
    except requests.exceptions.Timeout:
        return "Error: Request timed out. The model may be loading or overloaded."
    except Exception as e:
        return f"Error: {str(e)}"


def extract_sql_from_response(response: str) -> str:
    """Extract SQL query from LLM response."""
    import re
    # Look for SQL in code blocks
    sql_match = re.search(r'```sql\s*(.*?)\s*```', response, re.DOTALL | re.IGNORECASE)
    if sql_match:
        return sql_match.group(1).strip()
    # Look for SELECT statements
    select_match = re.search(r'(SELECT\s+.*?;)', response, re.DOTALL | re.IGNORECASE)
    if select_match:
        return select_match.group(1).strip()
    return ""


def check_ollama_status() -> bool:
    """Check if Ollama is available."""
    try:
        response = requests.get(f"{OLLAMA_HOST}/api/tags", timeout=5)
        return response.status_code == 200
    except Exception:
        return False


def check_openrouter_status() -> bool:
    """Check if OpenRouter API key is available."""
    key = get_openrouter_key()
    return key is not None and len(key) > 10


def query_openrouter(prompt: str, context: str = "") -> str:
    """Query OpenRouter API for natural language processing."""
    system_prompt = f"""You are a helpful assistant for a robotics intelligence database.
You help users query and understand data about the robotics industry.

{get_schema_info()}

When the user asks a question:
1. If they want data, generate a valid SQLite query
2. Wrap SQL queries in ```sql and ``` tags
3. Explain what the query does
4. If they ask for analysis, provide insights based on available data

{context}

Be concise and helpful."""

    try:
        api_key = get_openrouter_key()
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
                "HTTP-Referer": "https://robotics-intelligence.streamlit.app"
            },
            json={
                "model": OPENROUTER_MODEL,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                "max_tokens": 2000,
                "temperature": 0.3
            },
            timeout=60
        )
        response.raise_for_status()
        return response.json()['choices'][0]['message']['content']
    except requests.exceptions.Timeout:
        return "Error: Request timed out. Please try again."
    except Exception as e:
        return f"Error: {str(e)}"


def get_ai_backend() -> str:
    """Determine which AI backend is available."""
    if check_ollama_status():
        return "ollama"
    elif check_openrouter_status():
        return "openrouter"
    return None


# Sidebar
with st.sidebar:
    st.title("ü§ñ Robotics Intelligence")
    st.markdown("---")

    # Navigation
    page = st.radio(
        "Navigation",
        ["üìä Dashboard", "üè¢ Companies", "üìà Market Signals", "üîç Data Explorer", "üìë Technical Intelligence", "‚úÖ Validation", "üìã Methodology", "üí¨ AI Query Interface"],
        label_visibility="collapsed"
    )

    st.markdown("---")

    # AI Backend status
    ai_backend = get_ai_backend()
    if ai_backend == "ollama":
        st.success(f"‚úÖ AI: Ollama")
        st.caption(f"Model: {OLLAMA_MODEL}")
    elif ai_backend == "openrouter":
        st.success(f"‚úÖ AI: OpenRouter")
        st.caption(f"Model: Gemini Flash")
    else:
        st.warning("‚ö†Ô∏è AI Offline")
        st.caption("Configure OPENROUTER_KEY in secrets")

    st.markdown("---")
    st.caption(f"Database: {Path(DATABASE_PATH).name}")


# Main content based on selected page
if page == "üìä Dashboard":
    st.title("Robotics Intelligence Dashboard")

    # Key metrics row
    col1, col2, col3, col4 = st.columns(4)

    # Get counts
    data_points_count = run_query("SELECT COUNT(*) as count FROM data_points").iloc[0]['count']
    sectors_count = run_query("SELECT COUNT(*) as count FROM sectors").iloc[0]['count']
    sources_count = run_query("SELECT COUNT(*) as count FROM sources").iloc[0]['count']
    tech_count = run_query("SELECT COUNT(*) as count FROM technologies").iloc[0]['count']

    with col1:
        st.metric("üìà Data Points", f"{data_points_count:,}")
    with col2:
        st.metric("üè≠ Sectors", sectors_count)
    with col3:
        st.metric("üìö Sources", sources_count)
    with col4:
        st.metric("‚öôÔ∏è Technologies", tech_count)

    st.markdown("---")

    # Charts row
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Growth Rates by Sector")

        # Get growth rate data
        growth_query = """
            SELECT s.name as sector,
                   dp.value as growth_rate,
                   dp.year,
                   dp.confidence
            FROM data_points dp
            JOIN sectors s ON dp.sector_id = s.id
            JOIN dimensions d ON dp.dimension_id = d.id
            WHERE d.name = 'market_growth_rate'
            AND dp.value IS NOT NULL
            ORDER BY dp.value DESC
        """
        growth_df = run_query(growth_query)

        if not growth_df.empty:
            # Aggregate by sector (average if multiple years)
            sector_growth = growth_df.groupby('sector')['growth_rate'].mean().reset_index()
            sector_growth = sector_growth.sort_values('growth_rate', ascending=True)

            fig = px.bar(
                sector_growth,
                x='growth_rate',
                y='sector',
                orientation='h',
                title='Average Growth Rate by Sector (%)',
                labels={'growth_rate': 'Growth Rate (%)', 'sector': 'Sector'},
                color='growth_rate',
                color_continuous_scale='Viridis'
            )
            fig.update_layout(height=400, showlegend=False)
            st.plotly_chart(fig, width='stretch')
        else:
            st.info("No growth rate data available yet.")

    with col2:
        st.subheader("Market Size by Sector")

        # Get market size data
        market_query = """
            SELECT s.name as sector,
                   dp.value as market_size,
                   dp.year
            FROM data_points dp
            JOIN sectors s ON dp.sector_id = s.id
            JOIN dimensions d ON dp.dimension_id = d.id
            WHERE d.name = 'market_size'
            AND dp.value IS NOT NULL
            ORDER BY dp.value DESC
        """
        market_df = run_query(market_query)

        if not market_df.empty:
            # Get latest year for each sector
            latest_market = market_df.sort_values('year', ascending=False).groupby('sector').first().reset_index()

            fig = px.pie(
                latest_market,
                values='market_size',
                names='sector',
                title='Market Size Distribution (USD Billions)',
                hole=0.4
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, width='stretch')
        else:
            st.info("No market size data available yet.")

    # Data quality metrics
    st.markdown("---")
    st.subheader("Data Quality Overview")

    col1, col2 = st.columns(2)

    with col1:
        # Validation status breakdown
        validation_query = """
            SELECT validation_status, COUNT(*) as count
            FROM data_points
            GROUP BY validation_status
        """
        validation_df = run_query(validation_query)

        if not validation_df.empty:
            fig = px.pie(
                validation_df,
                values='count',
                names='validation_status',
                title='Data Validation Status',
                color='validation_status',
                color_discrete_map={
                    'validated': '#28a745',
                    'pending': '#ffc107',
                    'in_review': '#17a2b8',
                    'rejected': '#dc3545',
                    'outdated': '#6c757d'
                }
            )
            fig.update_layout(height=350)
            st.plotly_chart(fig, width='stretch')

    with col2:
        # Confidence level breakdown
        confidence_query = """
            SELECT confidence, COUNT(*) as count
            FROM data_points
            GROUP BY confidence
        """
        confidence_df = run_query(confidence_query)

        if not confidence_df.empty:
            fig = px.bar(
                confidence_df,
                x='confidence',
                y='count',
                title='Data Points by Confidence Level',
                color='confidence',
                color_discrete_map={
                    'high': '#28a745',
                    'medium': '#ffc107',
                    'low': '#fd7e14',
                    'unverified': '#dc3545'
                }
            )
            fig.update_layout(height=350, showlegend=False)
            st.plotly_chart(fig, width='stretch')


elif page == "üè¢ Companies":
    st.title("Company Profiles")
    st.markdown("Track robotics companies with funding history and status.")

    # Check if companies table exists
    try:
        companies_count = run_query("SELECT COUNT(*) as count FROM companies").iloc[0]['count']
    except:
        st.warning("Companies table not found. Run `python scripts/expand_schema.py` to create it.")
        st.stop()

    # Key metrics
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("üè¢ Total Companies", companies_count)
    with col2:
        startup_count = run_query("SELECT COUNT(*) as count FROM companies WHERE company_type = 'startup'").iloc[0]['count']
        st.metric("üöÄ Startups", startup_count)
    with col3:
        total_funding = run_query("SELECT SUM(total_funding_millions) as total FROM companies").iloc[0]['total'] or 0
        st.metric("üí∞ Total Funding", f"${total_funding:,.0f}M")
    with col4:
        funding_rounds = run_query("SELECT COUNT(*) as count FROM funding_rounds").iloc[0]['count']
        st.metric("üìä Funding Rounds", funding_rounds)

    st.markdown("---")

    # Filters
    col1, col2, col3 = st.columns(3)

    with col1:
        company_type_filter = st.selectbox(
            "Company Type",
            ["All", "startup", "enterprise", "public", "research"],
            key="company_type"
        )

    with col2:
        status_filter = st.selectbox(
            "Status",
            ["All", "active", "acquired", "defunct", "ipo"],
            key="company_status"
        )

    with col3:
        search_term = st.text_input("Search Company Name", key="company_search")

    # Build query
    company_query = """
        SELECT
            c.id,
            c.name,
            c.company_type,
            c.status,
            c.founded_year,
            c.hq_country,
            c.employee_count,
            c.total_funding_millions,
            c.website,
            (SELECT COUNT(*) FROM funding_rounds WHERE company_id = c.id) as funding_rounds,
            (SELECT MAX(announced_date) FROM funding_rounds WHERE company_id = c.id) as last_funding
        FROM companies c
        WHERE 1=1
    """
    params = []

    if company_type_filter != "All":
        company_query += " AND c.company_type = ?"
        params.append(company_type_filter)

    if status_filter != "All":
        company_query += " AND c.status = ?"
        params.append(status_filter)

    if search_term:
        company_query += " AND c.name LIKE ?"
        params.append(f"%{search_term}%")

    company_query += " ORDER BY c.total_funding_millions DESC NULLS LAST LIMIT 100"

    companies_df = run_query(company_query, tuple(params))

    st.subheader(f"Companies ({len(companies_df)} results)")

    if not companies_df.empty:
        for idx, row in companies_df.iterrows():
            # Status badge
            status_emoji = {"active": "üü¢", "acquired": "üîµ", "defunct": "üî¥", "ipo": "üü°"}.get(row['status'], "‚ö™")
            type_emoji = {"startup": "üöÄ", "enterprise": "üè¢", "public": "üìà", "research": "üî¨"}.get(row['company_type'], "")

            funding_display = f"${row['total_funding_millions']:,.0f}M" if row['total_funding_millions'] else "N/A"

            with st.expander(f"{status_emoji} {type_emoji} **{row['name']}** ‚Äî {funding_display} raised"):
                info_col1, info_col2 = st.columns(2)

                with info_col1:
                    st.markdown(f"""
| Field | Value |
|-------|-------|
| **Type** | {row['company_type'] or 'N/A'} |
| **Status** | {row['status'] or 'N/A'} |
| **Founded** | {int(row['founded_year']) if row['founded_year'] else 'N/A'} |
| **HQ** | {row['hq_country'] or 'N/A'} |
| **Employees** | {row['employee_count'] or 'N/A'} |
                    """)

                with info_col2:
                    st.markdown(f"""
| Funding | Value |
|---------|-------|
| **Total Raised** | {funding_display} |
| **Rounds** | {row['funding_rounds']} |
| **Last Funding** | {row['last_funding'] or 'N/A'} |
                    """)
                    if row['website']:
                        st.markdown(f"**Website:** [{row['website']}]({row['website']})")

                # Show funding rounds
                if row['funding_rounds'] > 0:
                    st.markdown("**Funding History:**")
                    rounds_df = run_query("""
                        SELECT round_type, amount_millions, announced_date, lead_investors
                        FROM funding_rounds
                        WHERE company_id = ?
                        ORDER BY announced_date DESC
                    """, (row['id'],))

                    for _, r in rounds_df.iterrows():
                        amount = f"${r['amount_millions']:,.0f}M" if r['amount_millions'] else "Undisclosed"
                        st.markdown(f"- **{r['round_type'] or 'Unknown'}**: {amount} ({r['announced_date'] or 'Date N/A'})")
    else:
        st.info("No companies match the selected filters.")

    # Top funded chart
    st.markdown("---")
    st.subheader("Top 10 Funded Companies")

    top_funded = run_query("""
        SELECT name, total_funding_millions, company_type
        FROM companies
        WHERE total_funding_millions IS NOT NULL AND total_funding_millions > 0
        ORDER BY total_funding_millions DESC
        LIMIT 10
    """)

    if not top_funded.empty:
        fig = px.bar(
            top_funded,
            x='total_funding_millions',
            y='name',
            orientation='h',
            color='company_type',
            labels={'total_funding_millions': 'Total Funding ($ Millions)', 'name': 'Company'},
            title='Top 10 Companies by Total Funding'
        )
        fig.update_layout(height=400, yaxis={'categoryorder': 'total ascending'})
        st.plotly_chart(fig, use_container_width=True)


elif page == "üìà Market Signals":
    st.title("Market Signals & Trends")
    st.markdown("Track funding announcements, partnerships, pain points, and adoption signals.")

    # Check if tables exist
    try:
        funding_count = run_query("SELECT COUNT(*) as count FROM funding_rounds").iloc[0]['count']
        partnership_count = run_query("SELECT COUNT(*) as count FROM partnerships").iloc[0]['count']
        pain_point_count = run_query("SELECT COUNT(*) as count FROM pain_points").iloc[0]['count']
    except:
        st.warning("Market signal tables not found. Run `python scripts/expand_schema.py` to create them.")
        st.stop()

    # Key metrics
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("üí∞ Funding Rounds", funding_count)
    with col2:
        st.metric("ü§ù Partnerships", partnership_count)
    with col3:
        st.metric("‚ö†Ô∏è Pain Points", pain_point_count)
    with col4:
        try:
            adoption_count = run_query("SELECT COUNT(*) as count FROM adoption_signals").iloc[0]['count']
        except:
            adoption_count = 0
        st.metric("üìä Adoption Signals", adoption_count)

    # Tabs for different signal types
    signal_tab1, signal_tab2, signal_tab3 = st.tabs(["üí∞ Recent Funding", "ü§ù Partnerships", "‚ö†Ô∏è Pain Points"])

    with signal_tab1:
        st.subheader("Recent Funding Rounds")

        funding_df = run_query("""
            SELECT
                fr.id,
                c.name as company,
                fr.round_type,
                fr.amount_millions,
                fr.announced_date,
                fr.lead_investors,
                fr.source_url
            FROM funding_rounds fr
            LEFT JOIN companies c ON fr.company_id = c.id
            ORDER BY fr.announced_date DESC, fr.id DESC
            LIMIT 50
        """)

        if not funding_df.empty:
            for _, row in funding_df.iterrows():
                amount = f"${row['amount_millions']:,.0f}M" if row['amount_millions'] else "Undisclosed"
                round_type = row['round_type'] or 'Unknown'

                # Color based on round type
                round_colors = {
                    'seed': 'üå±', 'series_a': 'üÖ∞Ô∏è', 'series_b': 'üÖ±Ô∏è',
                    'series_c': '¬©Ô∏è', 'series_d': 'üá©', 'series_e': 'üá™',
                    'growth': 'üìà', 'ipo': 'üîî', 'acquisition': 'üèÜ'
                }
                emoji = round_colors.get(round_type, 'üíµ')

                st.markdown(f"{emoji} **{row['company'] or 'Unknown Company'}** ‚Äî **{amount}** ({round_type})")
                st.caption(f"Announced: {row['announced_date'] or 'N/A'} | Lead: {row['lead_investors'] or 'N/A'}")
                if row['source_url']:
                    st.caption(f"[Source]({row['source_url']})")
                st.markdown("---")
        else:
            st.info("No funding rounds recorded yet. Run `python scripts/refresh_data.py --funding` to fetch data.")

        # Funding by round type chart
        funding_by_type = run_query("""
            SELECT round_type, COUNT(*) as count, SUM(amount_millions) as total_millions
            FROM funding_rounds
            WHERE round_type IS NOT NULL
            GROUP BY round_type
            ORDER BY total_millions DESC
        """)

        if not funding_by_type.empty:
            st.subheader("Funding by Round Type")
            fig = px.bar(
                funding_by_type,
                x='round_type',
                y='total_millions',
                color='count',
                labels={'round_type': 'Round Type', 'total_millions': 'Total Amount ($M)', 'count': 'Number of Rounds'},
                title='Total Funding by Round Type'
            )
            st.plotly_chart(fig, use_container_width=True)

    with signal_tab2:
        st.subheader("Strategic Partnerships")

        partnerships_df = run_query("""
            SELECT
                p.id,
                c1.name as company1,
                COALESCE(c2.name, p.company2_name) as company2,
                p.partnership_type,
                p.title,
                p.description,
                p.announcement_date,
                p.source_url
            FROM partnerships p
            LEFT JOIN companies c1 ON p.company1_id = c1.id
            LEFT JOIN companies c2 ON p.company2_id = c2.id
            ORDER BY p.announcement_date DESC, p.id DESC
            LIMIT 30
        """)

        if not partnerships_df.empty:
            for _, row in partnerships_df.iterrows():
                type_emoji = {
                    'integration': 'üîó', 'distribution': 'üì¶', 'manufacturing': 'üè≠',
                    'research': 'üî¨', 'investment': 'üí∞', 'acquisition': 'üèÜ',
                    'joint_venture': 'ü§ù', 'customer': 'üë§', 'supplier': 'üì§'
                }.get(row['partnership_type'], 'ü§ù')

                st.markdown(f"{type_emoji} **{row['company1'] or 'Company'}** ‚Üî **{row['company2'] or 'Partner'}**")
                if row['title']:
                    st.markdown(f"*{row['title']}*")
                if row['description']:
                    st.caption(row['description'][:200] + ('...' if len(row['description'] or '') > 200 else ''))
                st.caption(f"Type: {row['partnership_type'] or 'N/A'} | Date: {row['announcement_date'] or 'N/A'}")
                if row['source_url']:
                    st.caption(f"[Source]({row['source_url']})")
                st.markdown("---")
        else:
            st.info("No partnerships recorded yet. Run `python scripts/refresh_data.py --partnerships` to fetch data.")

    with signal_tab3:
        st.subheader("Industry Pain Points")

        pain_points_df = run_query("""
            SELECT
                pp.id,
                pp.title,
                pp.category,
                pp.scale,
                pp.severity,
                pp.description,
                pp.potential_solutions,
                pp.frequency_mentioned,
                s.name as sector
            FROM pain_points pp
            LEFT JOIN sectors s ON pp.sector_id = s.id
            ORDER BY pp.severity DESC, pp.frequency_mentioned DESC
            LIMIT 30
        """)

        if not pain_points_df.empty:
            for _, row in pain_points_df.iterrows():
                severity_emoji = {'critical': 'üî¥', 'high': 'üü†', 'medium': 'üü°', 'low': 'üü¢'}.get(row['severity'], '‚ö™')
                category_emoji = {
                    'technical': '‚öôÔ∏è', 'cost': 'üí∞', 'integration': 'üîó',
                    'workforce': 'üë∑', 'regulatory': 'üìú', 'safety': 'üõ°Ô∏è',
                    'scalability': 'üìà', 'reliability': 'üîß'
                }.get(row['category'], '‚ùì')

                st.markdown(f"{severity_emoji} {category_emoji} **{row['title']}**")
                st.caption(f"Category: {row['category']} | Severity: {row['severity']} | Scale: {row['scale']} | Sector: {row['sector'] or 'Industry-wide'}")
                if row['description']:
                    st.markdown(row['description'][:300] + ('...' if len(row['description'] or '') > 300 else ''))
                if row['potential_solutions']:
                    st.info(f"**Potential Solutions:** {row['potential_solutions'][:200]}")
                st.markdown("---")
        else:
            st.info("No pain points recorded yet. Run `python scripts/refresh_data.py --pain-points` to fetch data.")

        # Pain points by category chart
        pain_by_category = run_query("""
            SELECT category, COUNT(*) as count, severity
            FROM pain_points
            WHERE category IS NOT NULL
            GROUP BY category, severity
            ORDER BY count DESC
        """)

        if not pain_by_category.empty:
            st.subheader("Pain Points by Category")
            fig = px.bar(
                pain_by_category,
                x='category',
                y='count',
                color='severity',
                color_discrete_map={'critical': '#dc3545', 'high': '#fd7e14', 'medium': '#ffc107', 'low': '#28a745'},
                labels={'category': 'Category', 'count': 'Count', 'severity': 'Severity'},
                title='Pain Points Distribution'
            )
            st.plotly_chart(fig, use_container_width=True)


elif page == "üîç Data Explorer":
    st.title("Data Explorer")

    # Filters
    st.subheader("Filters")
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        sectors = run_query("SELECT name FROM sectors ORDER BY name")
        sector_filter = st.selectbox(
            "Sector",
            ["All"] + sectors['name'].tolist()
        )

    with col2:
        dimensions = run_query("SELECT name FROM dimensions ORDER BY name")
        dimension_filter = st.selectbox(
            "Dimension",
            ["All"] + dimensions['name'].tolist()
        )

    with col3:
        confidence_filter = st.selectbox(
            "Confidence",
            ["All", "high", "medium", "low", "unverified"]
        )

    with col4:
        validation_filter = st.selectbox(
            "Validation Status",
            ["All", "validated", "pending", "in_review", "rejected", "outdated"]
        )

    # Build query with filters
    query = """
        SELECT
            dp.id,
            s.name as sector,
            sc.name as subcategory,
            d.name as dimension,
            d.unit,
            dp.value,
            dp.value_text,
            dp.year,
            dp.quarter,
            dp.confidence,
            dp.validation_status,
            src.name as source,
            dp.notes,
            dp.created_at
        FROM data_points dp
        LEFT JOIN sectors s ON dp.sector_id = s.id
        LEFT JOIN subcategories sc ON dp.subcategory_id = sc.id
        LEFT JOIN dimensions d ON dp.dimension_id = d.id
        LEFT JOIN sources src ON dp.source_id = src.id
        WHERE 1=1
    """
    params = []

    if sector_filter != "All":
        query += " AND s.name = ?"
        params.append(sector_filter)

    if dimension_filter != "All":
        query += " AND d.name = ?"
        params.append(dimension_filter)

    if confidence_filter != "All":
        query += " AND dp.confidence = ?"
        params.append(confidence_filter)

    if validation_filter != "All":
        query += " AND dp.validation_status = ?"
        params.append(validation_filter)

    query += " ORDER BY dp.created_at DESC LIMIT 500"

    # Execute query
    df = run_query(query, tuple(params))

    # Display results
    st.markdown("---")
    st.subheader(f"Data Points ({len(df)} records)")

    if not df.empty:
        # Format the dataframe for display
        display_df = df.copy()

        # Combine value columns
        display_df['value_display'] = display_df.apply(
            lambda row: f"{row['value']:.2f} {row['unit']}" if pd.notna(row['value'])
            else (row['value_text'] if pd.notna(row['value_text']) else 'N/A'),
            axis=1
        )

        # Select columns to display
        display_cols = ['sector', 'subcategory', 'dimension', 'value_display',
                       'year', 'confidence', 'validation_status', 'source', 'notes']

        st.dataframe(
            display_df[display_cols],
            width='stretch',
            height=500,
            column_config={
                'sector': st.column_config.TextColumn('Sector', width='medium'),
                'subcategory': st.column_config.TextColumn('Subcategory', width='medium'),
                'dimension': st.column_config.TextColumn('Dimension', width='medium'),
                'value_display': st.column_config.TextColumn('Value', width='medium'),
                'year': st.column_config.NumberColumn('Year', format='%d'),
                'confidence': st.column_config.TextColumn('Confidence', width='small'),
                'validation_status': st.column_config.TextColumn('Status', width='small'),
                'source': st.column_config.TextColumn('Source', width='medium'),
                'notes': st.column_config.TextColumn('Notes', width='large'),
            }
        )

        # Download button
        csv = df.to_csv(index=False)
        st.download_button(
            label="üì• Download as CSV",
            data=csv,
            file_name="robotics_data_export.csv",
            mime="text/csv"
        )
    else:
        st.info("No data points match the selected filters.")

    # Technology data section
    st.markdown("---")
    st.subheader("Technology Data")

    tech_query = """
        SELECT
            t.name as technology,
            t.category,
            t.maturity_level,
            d.name as dimension,
            d.unit,
            tdp.value,
            tdp.year,
            tdp.confidence
        FROM technology_data_points tdp
        JOIN technologies t ON tdp.technology_id = t.id
        JOIN dimensions d ON tdp.dimension_id = d.id
        ORDER BY t.category, t.name
    """
    tech_df = run_query(tech_query)

    if not tech_df.empty:
        st.dataframe(tech_df, width='stretch', height=300)
    else:
        st.info("No technology data points available yet.")


elif page == "üìë Technical Intelligence":
    st.title("Technical Intelligence Reports")
    st.markdown("Deep-dive analysis of breakthroughs, R&D activity, patents, and technical hurdles by sector.")

    # Get list of reports
    reports_dir = project_root / "data" / "reports"

    if reports_dir.exists():
        report_files = list(reports_dir.glob("*_technical_intelligence.md"))

        if report_files:
            # Create sector selector
            sector_names = {
                "agricultural_robotics": "Agricultural Robotics",
                "construction_robotics": "Construction Robotics",
                "industrial_robotics": "Industrial Robotics",
                "logistics_robotics": "Logistics Robotics",
                "mobile_robotics": "Mobile Robotics",
                "service_robotics": "Service Robotics"
            }

            # Build options from available files
            available_sectors = []
            for f in sorted(report_files):
                key = f.stem.replace("_technical_intelligence", "")
                if key in sector_names:
                    available_sectors.append((sector_names[key], f))

            if available_sectors:
                selected_sector = st.selectbox(
                    "Select Sector",
                    options=[name for name, _ in available_sectors],
                    index=0
                )

                # Find the matching file
                selected_file = None
                for name, f in available_sectors:
                    if name == selected_sector:
                        selected_file = f
                        break

                if selected_file and selected_file.exists():
                    st.markdown("---")

                    # Read and display the report
                    content = selected_file.read_text(encoding='utf-8')

                    # Display report sections
                    st.markdown(content)

                    # Download button
                    st.markdown("---")
                    st.download_button(
                        label=f"üì• Download {selected_sector} Report",
                        data=content,
                        file_name=selected_file.name,
                        mime="text/markdown"
                    )
            else:
                st.warning("No reports found in the expected format.")
        else:
            st.info("No technical intelligence reports available yet.")
            st.markdown("""
            Run the expansion script to generate reports:
            ```bash
            python expand_robotics_db.py
            # Select option 4: Research technical innovations & R&D
            ```
            """)
    else:
        st.info("Reports directory not found. Creating...")
        reports_dir.mkdir(parents=True, exist_ok=True)
        st.markdown("Please add technical intelligence reports to `data/reports/`")


elif page == "‚úÖ Validation":
    st.title("Data Validation Workflow")
    st.markdown("Review and validate AI-generated data points and sources.")

    # Tabs for different validation tasks
    val_tab1, val_tab2, val_tab3 = st.tabs(["üìä Data Points", "üîó Sources", "üìà Statistics"])

    with val_tab1:
        st.subheader("Validate Data Points")

        # Filters
        col1, col2, col3 = st.columns(3)

        with col1:
            val_status_filter = st.selectbox(
                "Validation Status",
                ["pending", "All", "in_review", "validated", "rejected", "outdated"],
                key="dp_val_status"
            )

        with col2:
            conf_filter = st.selectbox(
                "Confidence Level",
                ["All", "high", "medium", "low", "unverified"],
                key="dp_conf"
            )

        with col3:
            sector_list = run_query("SELECT name FROM sectors ORDER BY name")
            sector_filter_val = st.selectbox(
                "Sector",
                ["All"] + sector_list['name'].tolist(),
                key="dp_sector"
            )

        # Build query with more details
        dp_query = """
            SELECT
                dp.id,
                dp.sector_id,
                s.name as sector,
                dp.subcategory_id,
                sub.name as subcategory,
                dp.dimension_id,
                d.name as dimension,
                d.unit as dimension_unit,
                dp.value,
                dp.value_text,
                dp.year,
                dp.confidence,
                dp.validation_status,
                dp.source_id,
                src.name as source_name,
                src.url as source_url,
                src.source_type,
                dp.notes
            FROM data_points dp
            LEFT JOIN sectors s ON dp.sector_id = s.id
            LEFT JOIN subcategories sub ON dp.subcategory_id = sub.id
            LEFT JOIN dimensions d ON dp.dimension_id = d.id
            LEFT JOIN sources src ON dp.source_id = src.id
            WHERE 1=1
        """
        params = []

        if val_status_filter != "All":
            dp_query += " AND dp.validation_status = ?"
            params.append(val_status_filter)

        if conf_filter != "All":
            dp_query += " AND dp.confidence = ?"
            params.append(conf_filter)

        if sector_filter_val != "All":
            dp_query += " AND s.name = ?"
            params.append(sector_filter_val)

        dp_query += " ORDER BY dp.id DESC LIMIT 100"

        dp_df = run_query(dp_query, tuple(params))

        # Get lookup data for dropdowns
        all_sectors = run_query("SELECT id, name FROM sectors ORDER BY name")
        all_dimensions = run_query("SELECT id, name, unit FROM dimensions ORDER BY name")
        all_subcategories = run_query("SELECT id, sector_id, name FROM subcategories ORDER BY name")

        st.markdown(f"**{len(dp_df)} data points** matching filters")

        if not dp_df.empty:
            for idx, row in dp_df.iterrows():
                with st.expander(f"ID {row['id']}: {row['sector']} ‚Üí {row['subcategory'] or 'General'} | {row['dimension']}"):

                    # Current Data Display (Clear formatting)
                    st.markdown("### üìä Current Data")

                    info_col1, info_col2 = st.columns(2)

                    with info_col1:
                        st.markdown(f"""
| Field | Value |
|-------|-------|
| **ID** | {row['id']} |
| **Sector** | {row['sector']} |
| **Subcategory** | {row['subcategory'] or '(none)'} |
| **Metric Type** | {row['dimension']} |
| **Unit** | {row['dimension_unit'] or 'see value_text'} |
                        """)

                    with info_col2:
                        # Format value with unit interpretation
                        unit = row['dimension_unit'] or ''
                        val = row['value']
                        val_text = row['value_text'] or ''

                        if row['dimension'] == 'market_size':
                            interpreted = f"${val} billion USD" if val else val_text
                        elif row['dimension'] == 'market_growth_rate':
                            interpreted = f"{val}% CAGR" if val else val_text
                        elif row['dimension'] == 'average_price':
                            interpreted = f"${val:,.0f} USD per unit" if val else val_text
                        elif row['dimension'] == 'r&d_investment':
                            interpreted = f"${val} million USD" if val else val_text
                        elif row['dimension'] == 'unit_shipments':
                            interpreted = f"{val:,.0f} units" if val else val_text
                        elif row['dimension'] == 'adoption_rate':
                            interpreted = f"{val}%" if val else val_text
                        elif row['dimension'] == 'roi_timeline':
                            interpreted = f"{val} months" if val else val_text
                        elif row['dimension'] == 'patents_filed':
                            interpreted = f"{val:,.0f} patents" if val else val_text
                        else:
                            interpreted = val_text if val_text else str(val)

                        # Safely convert year (might be float, NaN, or None)
                        try:
                            year_display = int(row['year']) if row['year'] and not pd.isna(row['year']) else 'N/A'
                        except (ValueError, TypeError):
                            year_display = 'N/A'

                        st.markdown(f"""
| Field | Value |
|-------|-------|
| **Numeric Value** | {val} |
| **Original Text** | {val_text or '(none)'} |
| **Interpreted As** | **{interpreted}** |
| **Year** | {year_display} |
                        """)

                    # Source Information with enrichment badges
                    st.markdown("### üîó Source Information")

                    source_name = row['source_name'] or 'Unknown'

                    # Detect company type from source name
                    if source_name.startswith('[STARTUP]'):
                        company_badge = "üöÄ **STARTUP**"
                        company_type = "startup"
                    elif source_name.startswith('[') and ']' in source_name:
                        company_name = source_name[1:source_name.index(']')]
                        company_badge = f"üè¢ **{company_name}**"
                        company_type = "established"
                    else:
                        company_badge = "üìä Research/Report"
                        company_type = "research"

                    # Detect verification status from notes
                    notes = row['notes'] or ''
                    if 'REQUIRES HUMAN VERIFICATION' in notes:
                        verification_badge = "‚ö†Ô∏è Needs Human Review"
                        verification_color = "warning"
                    elif 'VERIFIED' in notes or row['confidence'] == 'high':
                        verification_badge = "‚úÖ Verified Source"
                        verification_color = "success"
                    elif 'PARTIAL' in notes or row['confidence'] == 'medium':
                        verification_badge = "üîç Partially Verified"
                        verification_color = "info"
                    else:
                        verification_badge = "‚ùì Unverified"
                        verification_color = "error"

                    src_col1, src_col2 = st.columns(2)

                    with src_col1:
                        st.markdown(f"**Company Type:** {company_badge}")
                        st.markdown(f"**Source:** {source_name[:60]}{'...' if len(source_name) > 60 else ''}")
                        st.markdown(f"**Data Type:** `{row['source_type'] or 'unknown'}`")

                    with src_col2:
                        # Show verification status with appropriate styling
                        if verification_color == "success":
                            st.success(verification_badge)
                        elif verification_color == "info":
                            st.info(verification_badge)
                        elif verification_color == "warning":
                            st.warning(verification_badge)
                        else:
                            st.error(verification_badge)

                        st.markdown(f"**Confidence:** `{row['confidence'] or 'unverified'}`")

                    # URL section with smart detection
                    if row['source_url']:
                        url = row['source_url']
                        # Check if it's a specific document vs generic homepage
                        is_document = any(x in url.lower() for x in ['.pdf', '/report', '/filing', '/annual', 'sec.gov', 'q4cdn', 'press', 'news'])

                        if is_document:
                            st.success(f"üìÑ **Specific Document:** [{url[:70]}...]({url})")
                        else:
                            st.warning(f"üè† **Website (may need to search for data):** [{url[:50]}...]({url})")
                    else:
                        st.error("‚ùå No URL available - requires manual research")

                    # Notes with parsed verification details
                    if notes:
                        # Extract verification notes if present
                        if '[Verification:' in notes:
                            st.markdown("**Verification Notes:**")
                            st.caption(notes[:500] + ('...' if len(notes) > 500 else ''))
                        else:
                            st.markdown(f"**Notes:** {notes[:300]}{'...' if len(notes) > 300 else ''}")

                    st.markdown("---")

                    # Edit Section
                    st.markdown("### ‚úèÔ∏è Edit Data Point")

                    edit_col1, edit_col2 = st.columns(2)

                    with edit_col1:
                        # Editable fields
                        new_value = st.number_input(
                            "Numeric Value",
                            value=float(row['value']) if row['value'] else 0.0,
                            key=f"val_{row['id']}"
                        )

                        new_value_text = st.text_input(
                            "Value Text (with units)",
                            value=row['value_text'] or "",
                            key=f"valtxt_{row['id']}",
                            help="E.g., '120,000 units shipped globally' or '$4.2B market size'"
                        )

                        # Safely get year value
                        try:
                            year_val = int(row['year']) if row['year'] and not pd.isna(row['year']) else 2024
                        except (ValueError, TypeError):
                            year_val = 2024

                        new_year = st.number_input(
                            "Year",
                            value=year_val,
                            min_value=2000,
                            max_value=2035,
                            key=f"year_{row['id']}"
                        )

                        new_notes = st.text_area(
                            "Notes",
                            value=row['notes'] or "",
                            key=f"notes_{row['id']}",
                            help="Add context, caveats, or validation notes"
                        )

                    with edit_col2:
                        new_status = st.selectbox(
                            "Validation Status",
                            ["pending", "in_review", "validated", "rejected", "outdated"],
                            index=["pending", "in_review", "validated", "rejected", "outdated"].index(row['validation_status']) if row['validation_status'] in ["pending", "in_review", "validated", "rejected", "outdated"] else 0,
                            key=f"status_{row['id']}"
                        )

                        new_conf = st.selectbox(
                            "Confidence Level",
                            ["high", "medium", "low", "unverified"],
                            index=["high", "medium", "low", "unverified"].index(row['confidence']) if row['confidence'] in ["high", "medium", "low", "unverified"] else 1,
                            key=f"conf_{row['id']}",
                            help="high=verified source, medium=credible estimate, low=uncertain, unverified=needs review"
                        )

                        # Sector dropdown
                        sector_options = all_sectors['name'].tolist()
                        current_sector_idx = sector_options.index(row['sector']) if row['sector'] in sector_options else 0
                        new_sector = st.selectbox(
                            "Sector",
                            sector_options,
                            index=current_sector_idx,
                            key=f"sector_{row['id']}"
                        )

                        # Get subcategories for selected sector
                        new_sector_id = all_sectors[all_sectors['name'] == new_sector]['id'].iloc[0]
                        sector_subcats = all_subcategories[all_subcategories['sector_id'] == new_sector_id]['name'].tolist()
                        sector_subcats = ['(none)'] + sector_subcats

                        current_subcat = row['subcategory'] if row['subcategory'] else '(none)'
                        current_subcat_idx = sector_subcats.index(current_subcat) if current_subcat in sector_subcats else 0

                        new_subcategory = st.selectbox(
                            "Subcategory",
                            sector_subcats,
                            index=current_subcat_idx,
                            key=f"subcat_{row['id']}"
                        )

                    # Save button
                    if st.button("üíæ Save All Changes", key=f"save_{row['id']}", type="primary"):
                        conn = get_db_connection()
                        cursor = conn.cursor()

                        # Get new IDs
                        new_sector_id = all_sectors[all_sectors['name'] == new_sector]['id'].iloc[0]

                        new_subcat_id = None
                        if new_subcategory != '(none)':
                            subcat_match = all_subcategories[(all_subcategories['name'] == new_subcategory) & (all_subcategories['sector_id'] == new_sector_id)]
                            if not subcat_match.empty:
                                new_subcat_id = subcat_match['id'].iloc[0]

                        cursor.execute("""
                            UPDATE data_points
                            SET value = ?, value_text = ?, year = ?, notes = ?,
                                validation_status = ?, confidence = ?,
                                sector_id = ?, subcategory_id = ?,
                                validated_at = CURRENT_TIMESTAMP,
                                updated_at = CURRENT_TIMESTAMP
                            WHERE id = ?
                        """, (new_value, new_value_text, new_year, new_notes,
                              new_status, new_conf, new_sector_id, new_subcat_id, row['id']))
                        conn.commit()
                        st.success(f"‚úÖ Updated data point ID {row['id']}")
                        st.rerun()

    with val_tab2:
        st.subheader("Validate Sources")

        st.info("""
        **Source Validation Guide:**
        - **ai_generated** sources need URLs and verification
        - Distinguish between **Company Homepage** (e.g., irobot.com) and **Specific Report** (e.g., irobot.com/investor-relations/annual-report-2024.pdf)
        - Reliability: 0.0 = Unreliable, 0.5 = Needs verification, 0.8+ = Verified/trusted
        """)

        # Source type filter
        source_type_filter = st.selectbox(
            "Filter by Source Type",
            ["ai_generated", "All", "research_report", "news", "company", "government", "academic"],
            key="src_type"
        )

        # Build source query with more details
        src_query = """
            SELECT
                s.id,
                s.name,
                s.url,
                s.source_type,
                s.reliability_score,
                (SELECT COUNT(*) FROM data_points WHERE source_id = s.id) as data_point_count
            FROM sources s
            WHERE 1=1
        """
        src_params = []

        if source_type_filter != "All":
            src_query += " AND s.source_type = ?"
            src_params.append(source_type_filter)

        src_query += " ORDER BY data_point_count DESC, s.id DESC LIMIT 50"

        src_df = run_query(src_query, tuple(src_params))

        st.markdown(f"**{len(src_df)} sources** matching filters (sorted by usage)")

        if not src_df.empty:
            for idx, row in src_df.iterrows():
                # Determine status icon
                status_icon = "‚ö†Ô∏è" if row['source_type'] == 'ai_generated' else ("‚úÖ" if row['reliability_score'] and row['reliability_score'] >= 0.7 else "üîç")

                with st.expander(f"{status_icon} Source #{row['id']}: {row['name'][:50]}{'...' if len(row['name']) > 50 else ''} ‚Äî {row['data_point_count']} data points"):

                    # ===== CURRENT SOURCE INFO =====
                    st.markdown("### üìã Current Source Information")

                    info_col1, info_col2 = st.columns(2)
                    with info_col1:
                        st.markdown(f"**Source Name:** {row['name']}")
                        st.markdown(f"**Type:** `{row['source_type']}`")
                    with info_col2:
                        reliability = row['reliability_score'] if row['reliability_score'] else 0.5
                        reliability_label = "Unreliable" if reliability < 0.4 else ("Needs Review" if reliability < 0.7 else "Trusted")
                        st.markdown(f"**Reliability:** {reliability:.1f} ({reliability_label})")
                        st.markdown(f"**Data Points Using This:** {row['data_point_count']}")

                    # URL status
                    current_url = row['url'] or ""
                    # Check if it's a generic homepage vs specific report
                    is_generic = True  # Default to generic if no URL
                    if current_url:
                        is_generic = not any(x in current_url.lower() for x in ['report', 'pdf', 'research', 'press', 'news', 'article', 'publication', 'investor', 'annual'])
                        if is_generic:
                            st.warning(f"‚ö†Ô∏è **Generic URL detected:** [{current_url}]({current_url}) - This appears to be a company homepage, not a specific report")
                        else:
                            st.success(f"‚úÖ **Report URL:** [{current_url}]({current_url})")
                    else:
                        st.error("‚ùå **No URL set** - This source needs a URL")

                    # ===== DATA POINTS USING THIS SOURCE =====
                    st.markdown("### üìä Data Points Using This Source")
                    related_dp = run_query("""
                        SELECT
                            dp.id,
                            sec.name as sector,
                            dim.name as dimension,
                            dp.value,
                            dp.value_text,
                            dp.year
                        FROM data_points dp
                        JOIN sectors sec ON dp.sector_id = sec.id
                        JOIN dimensions dim ON dp.dimension_id = dim.id
                        WHERE dp.source_id = ?
                        LIMIT 5
                    """, (row['id'],))

                    if not related_dp.empty:
                        # Show a summary of what data uses this source
                        for _, dp in related_dp.iterrows():
                            value_display = dp['value_text'] if dp['value_text'] else str(dp['value'])
                            st.markdown(f"- **{dp['sector']}** ‚Üí {dp['dimension']}: {value_display} ({dp['year']})")

                        if row['data_point_count'] > 5:
                            st.caption(f"...and {row['data_point_count'] - 5} more data points")
                    else:
                        st.caption("No data points currently using this source")

                    # ===== EDIT SECTION =====
                    st.markdown("### ‚úèÔ∏è Edit Source")

                    edit_col1, edit_col2 = st.columns(2)

                    with edit_col1:
                        new_name = st.text_input(
                            "Source Name",
                            value=row['name'],
                            key=f"name_{row['id']}",
                            help="e.g., 'IFR World Robotics 2024' or 'McKinsey Global Institute'"
                        )

                        new_type = st.selectbox(
                            "Source Type",
                            ["ai_generated", "research_report", "news", "company", "government", "academic"],
                            index=["ai_generated", "research_report", "news", "company", "government", "academic"].index(row['source_type']) if row['source_type'] in ["ai_generated", "research_report", "news", "company", "government", "academic"] else 0,
                            key=f"type_{row['id']}",
                            help="ai_generated = Not verified | research_report = Industry report | company = Company disclosure"
                        )

                    with edit_col2:
                        new_reliability = st.slider(
                            "Reliability Score",
                            0.0, 1.0,
                            value=float(row['reliability_score']) if row['reliability_score'] else 0.5,
                            step=0.1,
                            key=f"rel_{row['id']}",
                            help="0.0 = Unreliable | 0.5 = Unverified | 0.8+ = Verified/trusted source"
                        )

                    st.markdown("**URLs:**")
                    url_col1, url_col2 = st.columns(2)

                    with url_col1:
                        # If URL looks like a specific report, pre-fill it here
                        report_url_value = current_url if (current_url and not is_generic) else ""
                        new_url = st.text_input(
                            "Specific Report/Article URL",
                            value=report_url_value,
                            key=f"url_{row['id']}",
                            help="Direct link to the specific report, PDF, or article containing the data"
                        )

                    with url_col2:
                        # If URL looks generic (homepage), pre-fill it here
                        homepage_url_value = current_url if (current_url and is_generic) else ""
                        company_url = st.text_input(
                            "Company/Publisher Homepage (optional)",
                            value=homepage_url_value,
                            key=f"compurl_{row['id']}",
                            help="e.g., irobot.com or mckinsey.com - used if no specific report URL is available"
                        )

                    # Use specific URL if provided, otherwise fall back to company URL
                    final_url = new_url.strip() if new_url.strip() else company_url.strip()

                    if st.button("üíæ Save Changes", key=f"save_src_{row['id']}"):
                        conn = get_db_connection()
                        cursor = conn.cursor()
                        cursor.execute("""
                            UPDATE sources
                            SET name = ?, url = ?, source_type = ?, reliability_score = ?
                            WHERE id = ?
                        """, (new_name, final_url, new_type, new_reliability, row['id']))
                        conn.commit()
                        st.success(f"‚úÖ Updated source #{row['id']}")
                        st.rerun()

    with val_tab3:
        st.subheader("Validation Statistics")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**Data Point Validation Status**")
            val_stats = run_query("""
                SELECT validation_status, COUNT(*) as count,
                       ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM data_points), 1) as percent
                FROM data_points
                GROUP BY validation_status
                ORDER BY count DESC
            """)
            st.dataframe(val_stats, hide_index=True, use_container_width=True)

            # Progress bar
            validated_count = val_stats[val_stats['validation_status'] == 'validated']['count'].sum() if 'validated' in val_stats['validation_status'].values else 0
            total_count = val_stats['count'].sum()
            progress = validated_count / total_count if total_count > 0 else 0
            st.progress(progress, text=f"{validated_count}/{total_count} validated ({progress*100:.1f}%)")

        with col2:
            st.markdown("**Source Types**")
            src_stats = run_query("""
                SELECT source_type, COUNT(*) as count,
                       ROUND(AVG(reliability_score), 2) as avg_reliability
                FROM sources
                GROUP BY source_type
                ORDER BY count DESC
            """)
            st.dataframe(src_stats, hide_index=True, use_container_width=True)

        st.markdown("---")

        st.markdown("**Confidence Level Distribution**")
        conf_stats = run_query("""
            SELECT confidence, COUNT(*) as count
            FROM data_points
            GROUP BY confidence
            ORDER BY count DESC
        """)

        import plotly.express as px
        fig = px.pie(conf_stats, values='count', names='confidence', title='Data Points by Confidence')
        st.plotly_chart(fig, use_container_width=True)

        # Quick actions
        st.markdown("---")
        st.subheader("Bulk Actions")

        col1, col2 = st.columns(2)

        with col1:
            if st.button("üîÑ Mark all 'high' confidence as 'validated'"):
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("""
                    UPDATE data_points
                    SET validation_status = 'validated', validated_at = CURRENT_TIMESTAMP
                    WHERE confidence = 'high' AND validation_status = 'pending'
                """)
                affected = cursor.rowcount
                conn.commit()
                st.success(f"Updated {affected} data points")

        with col2:
            if st.button("üîÑ Upgrade 'ai_generated' sources with URLs to 'research_report'"):
                conn = get_db_connection()
                cursor = conn.cursor()
                cursor.execute("""
                    UPDATE sources
                    SET source_type = 'research_report', reliability_score = 0.7
                    WHERE source_type = 'ai_generated' AND url IS NOT NULL AND url != ''
                """)
                affected = cursor.rowcount
                conn.commit()
                st.success(f"Updated {affected} sources")


elif page == "üìã Methodology":
    st.title("Data Methodology")
    st.markdown("How data is collected, categorized, and interpreted in this database.")

    st.markdown("---")

    # Data Collection
    st.header("1. Data Collection Process")
    st.markdown("""
    Data points are collected using **Kimi K2.5** AI via the OpenRouter API. The AI:
    1. Searches for quantitative robotics industry data
    2. Extracts specific metrics with sources
    3. Returns structured data in a consistent format

    Each data point includes:
    - **Sector** and **Subcategory** classification
    - **Dimension** (metric type)
    - **Value** (numeric) and **Value Text** (original with units)
    - **Year**, **Source**, and **Confidence Level**
    """)

    st.markdown("---")

    # Dimension Reference
    st.header("2. Dimension Reference (How to Interpret Values)")

    dimension_query = """
        SELECT name, unit, description,
               (SELECT COUNT(*) FROM data_points WHERE dimension_id = dimensions.id) as count
        FROM dimensions
        WHERE name NOT IN ('[correct enum]')
        ORDER BY count DESC
    """
    dim_df = run_query(dimension_query)

    st.markdown("Each dimension has a specific unit of measurement:")

    st.dataframe(
        dim_df,
        column_config={
            'name': st.column_config.TextColumn('Dimension', width='medium'),
            'unit': st.column_config.TextColumn('Unit', width='small'),
            'description': st.column_config.TextColumn('Description', width='large'),
            'count': st.column_config.NumberColumn('Data Points', format='%d')
        },
        hide_index=True,
        use_container_width=True
    )

    st.markdown("""
    **Interpreting Values:**

    | Dimension | Value Example | Interpretation |
    |-----------|---------------|----------------|
    | `market_size` | 4.2 | **$4.2 billion** USD |
    | `market_growth_rate` | 23.5 | **23.5% CAGR** (compound annual growth rate) |
    | `unit_shipments` | 125000 | **125,000 units** shipped |
    | `average_price` | 15000 | **$15,000 USD** per unit |
    | `r&d_investment` | 35 | **$35 million** USD investment |
    | `adoption_rate` | 34 | **34%** market penetration |
    | `roi_timeline` | 18 | **18 months** payback period |
    | `patents_filed` | 1247 | **1,247 patents** filed |
    | `performance_metric` | varies | See `value_text` for specific metric and units |
    | `technical_capability` | varies | See `value_text` for specific capability |

    **Note:** For dimensions marked "varies", always check the `value_text` column for the original
    text with units (e.g., "99.2% accuracy" or "50kg payload capacity").
    """)

    st.markdown("---")

    # Confidence Levels
    st.header("3. Confidence Levels")

    st.markdown("""
    | Level | Meaning | Source Quality |
    |-------|---------|----------------|
    | **high** | Verified from authoritative source | Company reports, peer-reviewed research, government data |
    | **medium** | Reasonable estimate from credible source | Industry reports, news articles, analyst estimates |
    | **low** | Uncertain or speculative | Blog posts, unverified claims, rough estimates |
    | **unverified** | Not yet validated | AI-generated, needs review |
    """)

    conf_query = """
        SELECT confidence, COUNT(*) as count,
               ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM data_points), 1) as percent
        FROM data_points
        GROUP BY confidence
        ORDER BY count DESC
    """
    conf_df = run_query(conf_query)
    st.dataframe(conf_df, hide_index=True)

    st.markdown("---")

    # Validation Status
    st.header("4. Validation Status")

    st.markdown("""
    | Status | Meaning |
    |--------|---------|
    | **pending** | Awaiting review |
    | **in_review** | Currently being validated |
    | **validated** | Confirmed accurate |
    | **rejected** | Found to be inaccurate |
    | **outdated** | Superseded by newer data |
    """)

    st.markdown("---")

    # Value Extraction
    st.header("5. Value Extraction Methodology")

    st.markdown("""
    **How numeric values are extracted from text:**

    ```
    Original Text: "$4.2B market size by 2025"
    ‚Üì
    Regex: r'[\\d,]+\\.?\\d*' extracts first number
    ‚Üì
    Numeric Value: 4.2
    ```

    **Limitations:**
    - Only the **first number** is extracted from text
    - For ranges like "12-18 months", only **12** is captured
    - Currency symbols and suffixes (B, M, K) are **not** factored into the numeric value
    - Always reference `value_text` for complete context

    **Best Practice:** When analyzing data, use:
    - `value` column for calculations and charts
    - `value_text` column for full context and units
    - `unit` from dimensions table for interpretation
    """)

    st.markdown("---")

    # Data Sources
    st.header("6. Source Types")

    source_query = """
        SELECT source_type, COUNT(*) as count
        FROM sources
        WHERE source_type IS NOT NULL
        GROUP BY source_type
        ORDER BY count DESC
    """
    source_df = run_query(source_query)

    if not source_df.empty:
        st.dataframe(source_df, hide_index=True)

    st.markdown("""
    **Source Reliability:**
    - Company filings and reports (high reliability)
    - Research firms (McKinsey, Gartner, IDC) (high reliability)
    - Industry associations (medium-high reliability)
    - News and press releases (medium reliability)
    - AI-generated estimates (requires validation)
    """)


elif page == "üí¨ AI Query Interface":
    st.title("AI Query Interface")
    st.markdown("Ask questions about the robotics database in natural language.")

    # Check AI backend status
    ai_backend = get_ai_backend()
    if not ai_backend:
        st.warning("**AI backend not configured.** Enter your OpenRouter API key below:")

        # API key input
        api_key_input = st.text_input(
            "OpenRouter API Key",
            type="password",
            placeholder="sk-or-v1-...",
            help="Get your key from https://openrouter.ai/keys"
        )

        if api_key_input:
            st.session_state.openrouter_key = api_key_input
            st.rerun()

        st.info("Your key is stored in session only (not saved permanently).")
        st.stop()
    else:
        st.success(f"‚úÖ Using **{ai_backend.upper()}** backend")
        # Example queries
        st.markdown("### Example Questions")
        example_cols = st.columns(2)

        examples = [
            "What sector has the highest growth rate?",
            "Show me all high-confidence market size data",
            "List all data points for Industrial Robotics",
            "What are the top 5 sectors by market size?",
            "Show validation status breakdown by sector",
            "Which technologies are marked as emerging?"
        ]

        for i, example in enumerate(examples):
            col = example_cols[i % 2]
            if col.button(f"üìù {example}", key=f"example_{i}"):
                st.session_state.query_input = example

        st.markdown("---")

        # Query input
        query_input = st.text_area(
            "Enter your question:",
            value=st.session_state.get('query_input', ''),
            height=100,
            placeholder="e.g., What sector has the highest growth rate?"
        )

        col1, col2 = st.columns([1, 5])
        with col1:
            submit_button = st.button("üîç Ask", type="primary")
        with col2:
            auto_execute = st.checkbox("Auto-execute SQL queries", value=True)

        if submit_button and query_input:
            with st.spinner("Thinking..."):
                # Get current data summary for context
                summary_query = """
                    SELECT
                        (SELECT COUNT(*) FROM data_points) as total_data_points,
                        (SELECT COUNT(*) FROM sectors) as total_sectors,
                        (SELECT COUNT(DISTINCT year) FROM data_points WHERE year IS NOT NULL) as years_covered
                """
                summary = run_query(summary_query).iloc[0]
                context = f"""
Current database contains:
- {summary['total_data_points']} data points
- {summary['total_sectors']} sectors
- Data from {summary['years_covered']} different years
"""

                # Query the LLM (use appropriate backend)
                if ai_backend == "ollama":
                    response = query_ollama(query_input, context)
                else:
                    response = query_openrouter(query_input, context)

                # Display response
                st.markdown("### Response")
                st.markdown(response)

                # Extract and optionally execute SQL
                sql_query = extract_sql_from_response(response)

                if sql_query and auto_execute:
                    st.markdown("### Query Results")
                    try:
                        # Validate it's a SELECT query (safety check)
                        if sql_query.strip().upper().startswith("SELECT"):
                            result_df = run_query(sql_query)
                            if not result_df.empty:
                                st.dataframe(result_df, width='stretch')

                                # Visualize if appropriate
                                if len(result_df.columns) >= 2 and len(result_df) > 1:
                                    numeric_cols = result_df.select_dtypes(include=['number']).columns.tolist()
                                    if numeric_cols:
                                        st.markdown("### Visualization")
                                        # Try to create a chart
                                        non_numeric = [c for c in result_df.columns if c not in numeric_cols]
                                        if non_numeric:
                                            x_col = non_numeric[0]
                                            y_col = numeric_cols[0]
                                            fig = px.bar(result_df, x=x_col, y=y_col)
                                            st.plotly_chart(fig, width='stretch')
                            else:
                                st.info("Query returned no results.")
                        else:
                            st.warning("Only SELECT queries are allowed for safety.")
                    except Exception as e:
                        st.error(f"Error executing query: {str(e)}")
                        st.code(sql_query, language="sql")
                elif sql_query:
                    st.markdown("### Generated SQL")
                    st.code(sql_query, language="sql")

        # Query history
        st.markdown("---")
        st.markdown("### Quick SQL Queries")

        quick_queries = {
            "Top sectors by data points": """
                SELECT s.name as sector, COUNT(*) as data_points
                FROM data_points dp
                JOIN sectors s ON dp.sector_id = s.id
                GROUP BY s.name
                ORDER BY data_points DESC
            """,
            "Growth rates by sector": """
                SELECT s.name as sector, dp.value as growth_rate, dp.year, dp.confidence
                FROM data_points dp
                JOIN sectors s ON dp.sector_id = s.id
                JOIN dimensions d ON dp.dimension_id = d.id
                WHERE d.name = 'market_growth_rate'
                ORDER BY dp.value DESC
            """,
            "High confidence data": """
                SELECT s.name as sector, d.name as dimension, dp.value, dp.year
                FROM data_points dp
                JOIN sectors s ON dp.sector_id = s.id
                JOIN dimensions d ON dp.dimension_id = d.id
                WHERE dp.confidence = 'high'
                ORDER BY dp.created_at DESC
                LIMIT 20
            """,
            "Market size summary": """
                SELECT s.name as sector,
                       dp.value as market_size_billions,
                       dp.year,
                       dp.confidence
                FROM data_points dp
                JOIN sectors s ON dp.sector_id = s.id
                JOIN dimensions d ON dp.dimension_id = d.id
                WHERE d.name = 'market_size'
                ORDER BY dp.value DESC
            """
        }

        selected_quick = st.selectbox("Select a quick query:", list(quick_queries.keys()))

        if st.button("‚ñ∂Ô∏è Run Quick Query"):
            sql = quick_queries[selected_quick]
            st.code(sql, language="sql")
            try:
                result_df = run_query(sql)
                st.dataframe(result_df, width='stretch')
            except Exception as e:
                st.error(f"Error: {str(e)}")


# Footer
st.markdown("---")
st.caption("Robotics Intelligence Database | Powered by Streamlit & Ollama")
